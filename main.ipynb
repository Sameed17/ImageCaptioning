{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os, pickle, torch, torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "def find_image_dir():\n",
    "    # Common Kaggle root\n",
    "\n",
    "    base_input = '/kaggle/input'\n",
    "    # Walk through the input directory to find where the images actually are\n",
    "    for root, dirs, files in os.walk(base_input):\n",
    "    # Look for the folder containing a high volume of jpg files\n",
    "        if len([f for f in files if f.endswith('.jpg')]) > 1000:\n",
    "            return root\n",
    "    return None\n",
    "IMAGE_DIR = find_image_dir()\n",
    "OUTPUT_FILE = 'flickr30k_features.pkl'\n",
    "if IMAGE_DIR:\n",
    "    print(f\" Found images at: {IMAGE_DIR}\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"Could not find the Flickr30k image directory. Please ensure the dataset is added to the notebook.\")\n",
    "# --- THE DATASET CLASS ---\n",
    "class FlickrDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform):\n",
    "        self.img_names = [f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.jpeg'))]\n",
    "        self.transform = transform\n",
    "        self.img_dir = img_dir\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "    def __getitem__(self, idx):\n",
    "        name = self.img_names[idx]\n",
    "        img_path = os.path.join(self.img_dir, name)\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        return self.transform(img), name\n",
    "# --- REMAINDER OF THE PIPELINE (AS BEFORE) ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "model = nn.Sequential(*list(model.children())[:-1]) # Feature vector only\n",
    "model = nn.DataParallel(model).to(device)\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "dataset = FlickrDataset(IMAGE_DIR, transform)\n",
    "loader = DataLoader(dataset, batch_size=128, num_workers=4)\n",
    "features_dict = {}\n",
    "with torch.no_grad():\n",
    "    for imgs, names in tqdm(loader, desc=\"Extracting Features\"):\n",
    "        feats = model(imgs.to(device)).view(imgs.size(0), -1)\n",
    "        for i, name in enumerate(names):\n",
    "            features_dict[name] = feats[i].cpu().numpy()\n",
    "with open(OUTPUT_FILE, 'wb') as f:\n",
    "    pickle.dump(features_dict, f)\n",
    "print(f\"Success! {len(features_dict)} images processed and saved to {OUTPUT_FILE}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
